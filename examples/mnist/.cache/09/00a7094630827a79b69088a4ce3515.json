{"id":"node_modules/@tensorflow/tfjs-layers/dist/engine/training_dataset.js","dependencies":[{"name":"/home/andu/Documents/git/web-dist-edge/examples/mnist/node_modules/@tensorflow/tfjs-layers/dist/engine/training_dataset.js.map","includedInParent":true,"mtime":1550574230668},{"name":"/home/andu/Documents/git/web-dist-edge/examples/mnist/package.json","includedInParent":true,"mtime":1550736445286},{"name":"/home/andu/Documents/git/web-dist-edge/examples/mnist/.babelrc","includedInParent":true,"mtime":1550128877340},{"name":"/home/andu/Documents/git/web-dist-edge/examples/mnist/node_modules/@tensorflow/tfjs-layers/package.json","includedInParent":true,"mtime":1550574230668},{"name":"@tensorflow/tfjs-core","loc":{"line":38,"column":18},"parent":"/home/andu/Documents/git/web-dist-edge/examples/mnist/node_modules/@tensorflow/tfjs-layers/dist/engine/training_dataset.js","resolved":"/home/andu/Documents/git/web-dist-edge/examples/mnist/node_modules/@tensorflow/tfjs-core/dist/tf-core.esm.js"},{"name":"../backend/state","loc":{"line":39,"column":22},"parent":"/home/andu/Documents/git/web-dist-edge/examples/mnist/node_modules/@tensorflow/tfjs-layers/dist/engine/training_dataset.js","resolved":"/home/andu/Documents/git/web-dist-edge/examples/mnist/node_modules/@tensorflow/tfjs-layers/dist/backend/state.js"},{"name":"../base_callbacks","loc":{"line":40,"column":31},"parent":"/home/andu/Documents/git/web-dist-edge/examples/mnist/node_modules/@tensorflow/tfjs-layers/dist/engine/training_dataset.js","resolved":"/home/andu/Documents/git/web-dist-edge/examples/mnist/node_modules/@tensorflow/tfjs-layers/dist/base_callbacks.js"},{"name":"../errors","loc":{"line":41,"column":23},"parent":"/home/andu/Documents/git/web-dist-edge/examples/mnist/node_modules/@tensorflow/tfjs-layers/dist/engine/training_dataset.js","resolved":"/home/andu/Documents/git/web-dist-edge/examples/mnist/node_modules/@tensorflow/tfjs-layers/dist/errors.js"},{"name":"../logs","loc":{"line":42,"column":21},"parent":"/home/andu/Documents/git/web-dist-edge/examples/mnist/node_modules/@tensorflow/tfjs-layers/dist/engine/training_dataset.js","resolved":"/home/andu/Documents/git/web-dist-edge/examples/mnist/node_modules/@tensorflow/tfjs-layers/dist/logs.js"},{"name":"../utils/generic_utils","loc":{"line":43,"column":30},"parent":"/home/andu/Documents/git/web-dist-edge/examples/mnist/node_modules/@tensorflow/tfjs-layers/dist/engine/training_dataset.js","resolved":"/home/andu/Documents/git/web-dist-edge/examples/mnist/node_modules/@tensorflow/tfjs-layers/dist/utils/generic_utils.js"}],"generated":{"js":"\"use strict\";\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = y[op[0] & 2 ? \"return\" : op[0] ? \"throw\" : \"next\"]) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [0, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar tfc = require(\"@tensorflow/tfjs-core\");\nvar state_1 = require(\"../backend/state\");\nvar base_callbacks_1 = require(\"../base_callbacks\");\nvar errors_1 = require(\"../errors\");\nvar logs_1 = require(\"../logs\");\nvar generic_utils_1 = require(\"../utils/generic_utils\");\nvar DEFAULT_VALIDATION_BATCH_SIZE = 32;\nfunction standardizeDataIteratorOutput(model, iteratorOut) {\n    if (model.outputs.length > 1) {\n        throw new errors_1.NotImplementedError(\"Support for training a model with multiple output tensors with \" +\n            \"a dataset object is not implemented yet.\");\n    }\n    tfc.util.assert(Array.isArray(iteratorOut) && iteratorOut.length === 2, 'Dataset iterator for fitDataset() is expected to generate ' +\n        'an Array of length 2: `[xs, ys]`, but instead generates ' +\n        iteratorOut);\n    var tuple = iteratorOut;\n    var xs = tuple[0];\n    var ys = tuple[1];\n    if (xs instanceof tfc.Tensor) {\n        tfc.util.assert(model.inputs.length === 1, \"Model has multiple \" + model.inputs.length + \" inputs, hence it \" +\n            \"expects the input dataset to generate a dictionary of tensors \" +\n            (\" (with keys \" + JSON.stringify(model.inputNames) + \", \") +\n            \"but received a single tensor.\");\n        tfc.util.assert(xs.shape[0] === ys.shape[0], \"Mismatch in batch size between x and y tensors (\" + xs.shape[0] + \" vs. \" +\n            (ys.shape[0] + \")\"));\n        return [xs, ys];\n    }\n    else {\n        var batchSize = void 0;\n        xs = xs;\n        var flattendXs = [];\n        for (var _i = 0, _a = model.inputNames; _i < _a.length; _i++) {\n            var inputName = _a[_i];\n            if (xs[inputName] == null) {\n                throw new errors_1.ValueError(\"The feature data generated by the dataset lacks the required \" +\n                    (\"input key '\" + inputName + \"'.\"));\n            }\n            flattendXs.push(xs[inputName]);\n            if (batchSize == null) {\n                batchSize = xs[inputName].shape[0];\n            }\n            else {\n                tfc.util.assert(xs[inputName].shape[0] === batchSize, \"Mismatch in batch size between x and y tensors \" +\n                    (\"(\" + xs[inputName].shape[0] + \" vs. \" + ys.shape[0] + \")\"));\n            }\n        }\n        return flattendXs.concat(ys);\n    }\n}\nfunction standardizeTensorValidationData(data) {\n    if (data.length === 3) {\n        throw new errors_1.NotImplementedError('Validation with sample weights is not implemented yet.');\n    }\n    return { xs: data[0], ys: data[1] };\n}\nfunction fitDataset(model, dataset, args) {\n    return __awaiter(this, void 0, void 0, function () {\n        var hasBatchesPerEpoch, doValidation, valXs, valYs, validationData, trainFunction, outLabels, callbackMetrics, callbacks, verbose, _a, callbackList, history_1, epoch, dataIterator, epochLogs, stepsDone, batchIndex, iteratorOut, xsAndYs, batchLogs, outs, i, label, out, valOuts, _b, i;\n        return __generator(this, function (_c) {\n            switch (_c.label) {\n                case 0:\n                    hasBatchesPerEpoch = args.batchesPerEpoch != null;\n                    tfc.util.assert(model.optimizer != null, 'You must compile a model before training/testing. Use ' +\n                        'Model.compile(modelCompileConfig).');\n                    tfc.util.assert(args != null, \"For fitDataset(), the 2nd argument (config) is required, \" +\n                        \"but it is not provided in this call.\");\n                    tfc.util.assert(args.epochs != null && args.epochs > 0 && Number.isInteger(args.epochs), \"For fitDataset(), config.epochs is expected to be a positive \" +\n                        (\"integer, but got \" + args.epochs));\n                    tfc.util.assert(!hasBatchesPerEpoch ||\n                        (args.batchesPerEpoch > 0 && Number.isInteger(args.batchesPerEpoch)), \"For fitDataset(), config.batchesPerEpoch is expected to be a \" +\n                        (\"positive integer if specified, but got \" + args.batchesPerEpoch));\n                    tfc.util.assert(args['validationSplit'] == null, '`validationSplit` is not supported by `fitDataset()`. ' +\n                        'Use validationData instead.');\n                    if (model.isTraining) {\n                        throw new Error('Cannot start training because another fit() call is ongoing.');\n                    }\n                    model.isTraining = true;\n                    _c.label = 1;\n                case 1:\n                    _c.trys.push([1, , 22, 23]);\n                    doValidation = args.validationData != null;\n                    valXs = void 0;\n                    valYs = void 0;\n                    if (doValidation) {\n                        if (isDatasetObject(args.validationData)) {\n                            tfc.util.assert(args.validationBatches == null ||\n                                (args.validationBatches > 0 &&\n                                    Number.isInteger(args.validationBatches)), \"For fitDataset() with dataset-based validation, \" +\n                                \"config.validationBatches is expected not to be provided, \" +\n                                \"or to be a positive integer, \" +\n                                (\"but got \" + args.validationBatches));\n                        }\n                        else {\n                            validationData = standardizeTensorValidationData(args.validationData);\n                            valXs = validationData.xs;\n                            valYs = validationData.ys;\n                        }\n                    }\n                    trainFunction = model.makeTrainFunction();\n                    outLabels = model.getDedupedMetricsNames();\n                    callbackMetrics = void 0;\n                    if (doValidation) {\n                        callbackMetrics =\n                            outLabels.slice().concat(outLabels.map(function (n) { return 'val_' + n; }));\n                    }\n                    else {\n                        callbackMetrics = outLabels.slice();\n                    }\n                    callbacks = base_callbacks_1.standardizeCallbacks(args.callbacks);\n                    verbose = args.verbose == null ? 1 : args.verbose;\n                    _a = base_callbacks_1.configureCallbacks(callbacks, args.yieldEvery, verbose, args.epochs, null, null, getStepsPerEpoch(dataset, args), null, doValidation, callbackMetrics), callbackList = _a.callbackList, history_1 = _a.history;\n                    callbackList.setModel(model);\n                    model.history = history_1;\n                    return [4, callbackList.onTrainBegin()];\n                case 2:\n                    _c.sent();\n                    model.stopTraining_ = false;\n                    epoch = args.initialEpoch == null ? 0 : args.initialEpoch;\n                    return [4, dataset.iterator()];\n                case 3:\n                    dataIterator = _c.sent();\n                    _c.label = 4;\n                case 4:\n                    if (!(epoch < args.epochs)) return [3, 19];\n                    epochLogs = {};\n                    return [4, callbackList.onEpochBegin(epoch)];\n                case 5:\n                    _c.sent();\n                    stepsDone = 0;\n                    batchIndex = 0;\n                    if (!!hasBatchesPerEpoch) return [3, 7];\n                    return [4, dataset.iterator()];\n                case 6:\n                    dataIterator = _c.sent();\n                    _c.label = 7;\n                case 7:\n                    if (!(hasBatchesPerEpoch ? stepsDone < args.batchesPerEpoch : true)) return [3, 17];\n                    return [4, dataIterator.next()];\n                case 8:\n                    iteratorOut = _c.sent();\n                    if (hasBatchesPerEpoch && iteratorOut.done) {\n                        console.warn('You provided `batchesPerEpoch` as ' +\n                            (args.batchesPerEpoch + \", \") +\n                            'but your dataset iterator ran out of data after ' +\n                            (stepsDone + \" batches; \") +\n                            'interrupting training. Make sure that your ' +\n                            'dataset can generate at least `batchesPerEpoch * epochs` ' +\n                            'batches (in this case, ' +\n                            (args.batchesPerEpoch * args.epochs + \" batches). \") +\n                            'You may need to use the repeat() function when building ' +\n                            'your dataset.');\n                        return [3, 17];\n                    }\n                    if (!(iteratorOut.value != null)) return [3, 11];\n                    xsAndYs = standardizeDataIteratorOutput(model, iteratorOut.value);\n                    batchLogs = {};\n                    batchLogs['batch'] = batchIndex;\n                    batchLogs['size'] = xsAndYs[0].shape[0];\n                    return [4, callbackList.onBatchBegin(batchIndex, batchLogs)];\n                case 9:\n                    _c.sent();\n                    outs = trainFunction(xsAndYs);\n                    tfc.dispose(xsAndYs);\n                    for (i = 0; i < outLabels.length; ++i) {\n                        label = outLabels[i];\n                        out = outs[i];\n                        batchLogs[label] = out;\n                        tfc.keep(out);\n                    }\n                    return [4, callbackList.onBatchEnd(batchIndex, batchLogs)];\n                case 10:\n                    _c.sent();\n                    logs_1.disposeTensorsInLogs(batchLogs);\n                    batchIndex++;\n                    stepsDone++;\n                    _c.label = 11;\n                case 11:\n                    if (!(hasBatchesPerEpoch ? stepsDone >= args.batchesPerEpoch :\n                        iteratorOut.done)) return [3, 16];\n                    if (!doValidation) return [3, 15];\n                    valOuts = void 0;\n                    if (!isDatasetObject(args.validationData)) return [3, 13];\n                    _b = generic_utils_1.toList;\n                    return [4, model.evaluateDataset(args.validationData, { batches: args.validationBatches })];\n                case 12:\n                    valOuts = _b.apply(void 0, [_c.sent()]);\n                    return [3, 14];\n                case 13:\n                    valOuts = generic_utils_1.toList(model.evaluate(valXs, valYs, {\n                        batchSize: args.validationBatchSize == null ?\n                            DEFAULT_VALIDATION_BATCH_SIZE :\n                            args.validationBatchSize,\n                        verbose: 0\n                    }));\n                    _c.label = 14;\n                case 14:\n                    for (i = 0; i < model.metricsNames.length; ++i) {\n                        epochLogs[\"val_\" + model.metricsNames[i]] = valOuts[i];\n                    }\n                    _c.label = 15;\n                case 15: return [3, 17];\n                case 16:\n                    if (model.stopTraining_) {\n                        return [3, 17];\n                    }\n                    return [3, 7];\n                case 17: return [4, callbackList.onEpochEnd(epoch, epochLogs)];\n                case 18:\n                    _c.sent();\n                    epoch++;\n                    if (model.stopTraining_) {\n                        return [3, 19];\n                    }\n                    return [3, 4];\n                case 19: return [4, callbackList.onTrainEnd()];\n                case 20:\n                    _c.sent();\n                    return [4, model.history.syncData()];\n                case 21:\n                    _c.sent();\n                    return [2, model.history];\n                case 22:\n                    model.isTraining = false;\n                    return [7];\n                case 23: return [2];\n            }\n        });\n    });\n}\nexports.fitDataset = fitDataset;\nfunction getStepsPerEpoch(dataset, args) {\n    var stepsPerEpoch = null;\n    if (args.batchesPerEpoch != null) {\n        stepsPerEpoch = args.batchesPerEpoch;\n    }\n    else if (Number.isFinite(dataset.size)) {\n        stepsPerEpoch = dataset.size;\n    }\n    return stepsPerEpoch;\n}\nfunction isDatasetObject(dataset) {\n    return (typeof dataset.iterator === 'function');\n}\nfunction isLazyIteratorObject(iterator) {\n    return (typeof iterator.next === 'function');\n}\nfunction evaluateDataset(model, dataset, args) {\n    return __awaiter(this, void 0, void 0, function () {\n        var hasBatches, f, outs, dataIterator, _a, numExamples, batch, _loop_1, state_2, _loop_2, i;\n        return __generator(this, function (_b) {\n            switch (_b.label) {\n                case 0:\n                    args = args || {};\n                    hasBatches = args.batches != null;\n                    f = model.testFunction;\n                    outs = [];\n                    if (args.verbose > 0) {\n                        throw new errors_1.NotImplementedError('Verbose mode is not implemented yet.');\n                    }\n                    tfc.util.assert(!hasBatches || (args.batches > 0 && Number.isInteger(args.batches)), 'Test loop expects `batches` to be a positive integer, but ' +\n                        (\"received \" + JSON.stringify(args.batches)));\n                    if (!isLazyIteratorObject(dataset)) return [3, 1];\n                    _a = dataset;\n                    return [3, 3];\n                case 1: return [4, dataset.iterator()];\n                case 2:\n                    _a = _b.sent();\n                    _b.label = 3;\n                case 3:\n                    dataIterator = _a;\n                    numExamples = 0;\n                    batch = 0;\n                    _loop_1 = function () {\n                        var iteratorOut, xsAndYs_1, batchOuts, i, batchSize_1, _loop_3, i;\n                        return __generator(this, function (_a) {\n                            switch (_a.label) {\n                                case 0: return [4, dataIterator.next()];\n                                case 1:\n                                    iteratorOut = _a.sent();\n                                    if (iteratorOut.value) {\n                                        xsAndYs_1 = standardizeDataIteratorOutput(model, iteratorOut.value);\n                                        batchOuts = tfc.tidy(function () { return f(xsAndYs_1); });\n                                        tfc.dispose(xsAndYs_1);\n                                        if (batch === 0) {\n                                            for (i = 0; i < batchOuts.length; ++i) {\n                                                outs.push(state_1.getScalar(0));\n                                            }\n                                        }\n                                        batchSize_1 = xsAndYs_1[0].shape[0];\n                                        _loop_3 = function (i) {\n                                            var batchOut = batchOuts[i];\n                                            var oldScalar = outs[i];\n                                            outs[i] = tfc.tidy(function () { return tfc.add(outs[i], tfc.mul(state_1.getScalar(batchSize_1), batchOut)); });\n                                            if (batch > 0) {\n                                                tfc.dispose(oldScalar);\n                                            }\n                                        };\n                                        for (i = 0; i < batchOuts.length; ++i) {\n                                            _loop_3(i);\n                                        }\n                                        tfc.dispose(batchOuts);\n                                        numExamples += batchSize_1;\n                                        ++batch;\n                                    }\n                                    if (iteratorOut.done) {\n                                        if (hasBatches) {\n                                            console.warn('Your dataset iterator ran out of data during evaluateDataset(). ' +\n                                                'Interrupting evalution. Make sure that your ' +\n                                                'dataset can generate at least `batches` ' +\n                                                (\"batches (in this case, \" + args.batches + \" batches). \") +\n                                                'You may need to use the repeat() function when building ' +\n                                                'your dataset.');\n                                        }\n                                        return [2, \"break\"];\n                                    }\n                                    return [2];\n                            }\n                        });\n                    };\n                    _b.label = 4;\n                case 4:\n                    if (!(hasBatches ? batch < args.batches : true)) return [3, 6];\n                    return [5, _loop_1()];\n                case 5:\n                    state_2 = _b.sent();\n                    if (state_2 === \"break\")\n                        return [3, 6];\n                    return [3, 4];\n                case 6:\n                    _loop_2 = function (i) {\n                        var oldScalar = outs[i];\n                        outs[i] =\n                            tfc.tidy(function () { return tfc.div(outs[i], state_1.getScalar(numExamples)); });\n                        tfc.dispose(oldScalar);\n                    };\n                    for (i = 0; i < outs.length; ++i) {\n                        _loop_2(i);\n                    }\n                    return [2, generic_utils_1.singletonOrArray(outs)];\n            }\n        });\n    });\n}\nexports.evaluateDataset = evaluateDataset;\n","map":{"version":3,"file":"training_dataset.js","sourceRoot":"","sources":["../../src/engine/training_dataset.ts"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAcA,2CAA6C;AAC7C,0CAA2C;AAC3C,oDAAgK;AAChK,oCAA0D;AAC1D,gCAA6D;AAC7D,wDAAgE;AAyIhE,IAAM,6BAA6B,GAAG,EAAE,CAAC;AAYzC,uCAGI,KAAU,EAAE,WAAe;IAC7B,IAAI,KAAK,CAAC,OAAO,CAAC,MAAM,GAAG,CAAC,EAAE;QAC5B,MAAM,IAAI,4BAAmB,CACzB,iEAAiE;YACjE,0CAA0C,CAAC,CAAC;KACjD;IAED,GAAG,CAAC,IAAI,CAAC,MAAM,CACX,KAAK,CAAC,OAAO,CAAC,WAAW,CAAC,IAAI,WAAW,CAAC,MAAM,KAAK,CAAC,EACtD,4DAA4D;QACxD,0DAA0D;QAC1D,WAAW,CAAC,CAAC;IAGrB,IAAM,KAAK,GAAG,WAA8C,CAAC;IAC7D,IAAI,EAAE,GAAG,KAAK,CAAC,CAAC,CAAC,CAAC;IAClB,IAAM,EAAE,GAAG,KAAK,CAAC,CAAC,CAAC,CAAC;IACpB,IAAI,EAAE,YAAY,GAAG,CAAC,MAAM,EAAE;QAC5B,GAAG,CAAC,IAAI,CAAC,MAAM,CACX,KAAK,CAAC,MAAM,CAAC,MAAM,KAAK,CAAC,EACzB,wBAAsB,KAAK,CAAC,MAAM,CAAC,MAAM,uBAAoB;YACzD,gEAAgE;aAChE,iBAAe,IAAI,CAAC,SAAS,CAAC,KAAK,CAAC,UAAU,CAAC,OAAI,CAAA;YACnD,+BAA+B,CAAC,CAAC;QACzC,GAAG,CAAC,IAAI,CAAC,MAAM,CACX,EAAE,CAAC,KAAK,CAAC,CAAC,CAAC,KAAK,EAAE,CAAC,KAAK,CAAC,CAAC,CAAC,EAC3B,qDAAmD,EAAE,CAAC,KAAK,CAAC,CAAC,CAAC,UAAO;aAC9D,EAAE,CAAC,KAAK,CAAC,CAAC,CAAC,MAAG,CAAA,CAAC,CAAC;QAC3B,OAAO,CAAC,EAAE,EAAE,EAAE,CAAC,CAAC;KACjB;SAAM;QACL,IAAI,SAAS,SAAQ,CAAC;QACtB,EAAE,GAAG,EAAe,CAAC;QACrB,IAAM,UAAU,GAAiB,EAAE,CAAC;QAGpC,KAAwB,UAAgB,EAAhB,KAAA,KAAK,CAAC,UAAU,EAAhB,cAAgB,EAAhB,IAAgB;YAAnC,IAAM,SAAS,SAAA;YAClB,IAAI,EAAE,CAAC,SAAS,CAAC,IAAI,IAAI,EAAE;gBACzB,MAAM,IAAI,mBAAU,CAChB,+DAA+D;qBAC/D,gBAAc,SAAS,OAAI,CAAA,CAAC,CAAC;aAClC;YACD,UAAU,CAAC,IAAI,CAAC,EAAE,CAAC,SAAS,CAAC,CAAC,CAAC;YAC/B,IAAI,SAAS,IAAI,IAAI,EAAE;gBACrB,SAAS,GAAG,EAAE,CAAC,SAAS,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;aACpC;iBAAM;gBACL,GAAG,CAAC,IAAI,CAAC,MAAM,CACX,EAAE,CAAC,SAAS,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,KAAK,SAAS,EACpC,iDAAiD;qBAC7C,MAAI,EAAE,CAAC,SAAS,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,aAAQ,EAAE,CAAC,KAAK,CAAC,CAAC,CAAC,MAAG,CAAA,CAAC,CAAC;aAC3D;SACF;QACD,OAAO,UAAU,CAAC,MAAM,CAAC,EAAE,CAAC,CAAC;KAC9B;AAGH,CAAC;AAED,yCACI,IAIiC;IAEnC,IAAI,IAAI,CAAC,MAAM,KAAK,CAAC,EAAE;QACrB,MAAM,IAAI,4BAAmB,CACzB,wDAAwD,CAAC,CAAC;KAC/D;IACD,OAAO,EAAC,EAAE,EAAE,IAAI,CAAC,CAAC,CAAC,EAAE,EAAE,EAAE,IAAI,CAAC,CAAC,CAAC,EAAC,CAAC;AACpC,CAAC;AAED,oBAGI,KAAU,EAAE,OAAmB,EAC/B,IAA4B;;;;;;oBACxB,kBAAkB,GAAG,IAAI,CAAC,eAAe,IAAI,IAAI,CAAC;oBACxD,GAAG,CAAC,IAAI,CAAC,MAAM,CACX,KAAK,CAAC,SAAS,IAAI,IAAI,EACvB,wDAAwD;wBACpD,oCAAoC,CAAC,CAAC;oBAE9C,GAAG,CAAC,IAAI,CAAC,MAAM,CACX,IAAI,IAAI,IAAI,EACZ,2DAA2D;wBACvD,sCAAsC,CAAC,CAAC;oBAChD,GAAG,CAAC,IAAI,CAAC,MAAM,CACX,IAAI,CAAC,MAAM,IAAI,IAAI,IAAI,IAAI,CAAC,MAAM,GAAG,CAAC,IAAI,MAAM,CAAC,SAAS,CAAC,IAAI,CAAC,MAAM,CAAC,EACvE,+DAA+D;yBAC3D,sBAAoB,IAAI,CAAC,MAAQ,CAAA,CAAC,CAAC;oBAC3C,GAAG,CAAC,IAAI,CAAC,MAAM,CACX,CAAC,kBAAkB;wBACf,CAAC,IAAI,CAAC,eAAe,GAAG,CAAC,IAAI,MAAM,CAAC,SAAS,CAAC,IAAI,CAAC,eAAe,CAAC,CAAC,EACxE,+DAA+D;yBAC3D,4CAA0C,IAAI,CAAC,eAAiB,CAAA,CAAC,CAAC;oBAC1E,GAAG,CAAC,IAAI,CAAC,MAAM,CAEV,IAAY,CAAC,iBAAiB,CAAC,IAAI,IAAI,EACxC,wDAAwD;wBACpD,6BAA6B,CAAC,CAAC;oBAEvC,IAAI,KAAK,CAAC,UAAU,EAAE;wBACpB,MAAM,IAAI,KAAK,CACX,8DAA8D,CAAC,CAAC;qBACrE;oBACD,KAAK,CAAC,UAAU,GAAG,IAAI,CAAC;;;;oBAGhB,YAAY,GAAG,IAAI,CAAC,cAAc,IAAI,IAAI,CAAC;oBAC7C,KAAK,SAAyB,CAAC;oBAC/B,KAAK,SAAyB,CAAC;oBACnC,IAAI,YAAY,EAAE;wBAChB,IAAI,eAAe,CAAC,IAAI,CAAC,cAAc,CAAC,EAAE;4BACxC,GAAG,CAAC,IAAI,CAAC,MAAM,CACX,IAAI,CAAC,iBAAiB,IAAI,IAAI;gCAC1B,CAAC,IAAI,CAAC,iBAAiB,GAAG,CAAC;oCAC1B,MAAM,CAAC,SAAS,CAAC,IAAI,CAAC,iBAAiB,CAAC,CAAC,EAC9C,kDAAkD;gCAC9C,2DAA2D;gCAC3D,+BAA+B;iCAC/B,aAAW,IAAI,CAAC,iBAAmB,CAAA,CAAC,CAAC;yBAC9C;6BAAM;4BACC,cAAc,GAAG,+BAA+B,CAClD,IAAI,CAAC,cAKJ,CAAC,CAAC;4BACP,KAAK,GAAG,cAAc,CAAC,EAAE,CAAC;4BAC1B,KAAK,GAAG,cAAc,CAAC,EAAE,CAAC;yBAC3B;qBACF;oBAEK,aAAa,GAAG,KAAK,CAAC,iBAAiB,EAAE,CAAC;oBAC1C,SAAS,GAAG,KAAK,CAAC,sBAAsB,EAAc,CAAC;oBAEzD,eAAe,SAAU,CAAC;oBAC9B,IAAI,YAAY,EAAE;wBAChB,eAAe;4BACX,SAAS,CAAC,KAAK,EAAE,CAAC,MAAM,CAAC,SAAS,CAAC,GAAG,CAAC,UAAA,CAAC,IAAI,OAAA,MAAM,GAAG,CAAC,EAAV,CAAU,CAAC,CAAC,CAAC;qBAC9D;yBAAM;wBACL,eAAe,GAAG,SAAS,CAAC,KAAK,EAAE,CAAC;qBACrC;oBAEK,SAAS,GAAG,qCAAoB,CAAC,IAAI,CAAC,SAAS,CAAC,CAAC;oBACjD,OAAO,GAAG,IAAI,CAAC,OAAO,IAAI,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,OAAO,CAAC;oBAClD,KAA0B,mCAAkB,CAC9C,SAAS,EAAE,IAAI,CAAC,UAAU,EAAE,OAAO,EAAE,IAAI,CAAC,MAAM,EAAE,IAAI,EAAE,IAAI,EAC5D,gBAAgB,CAAC,OAAO,EAAE,IAAI,CAAC,EAC/B,IAAI,EACJ,YAAY,EAAE,eAAe,CAAC,EAJ3B,YAAY,kBAAA,EAAE,sBAAO,CAIO;oBACnC,YAAY,CAAC,QAAQ,CAAC,KAAK,CAAC,CAAC;oBAC7B,KAAK,CAAC,OAAO,GAAG,SAAO,CAAC;oBAExB,WAAM,YAAY,CAAC,YAAY,EAAE,EAAA;;oBAAjC,SAAiC,CAAC;oBAClC,KAAK,CAAC,aAAa,GAAG,KAAK,CAAC;oBACxB,KAAK,GAAG,IAAI,CAAC,YAAY,IAAI,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,YAAY,CAAC;oBAE3C,WAAM,OAAO,CAAC,QAAQ,EAAE,EAAA;;oBAAvC,YAAY,GAAG,SAAwB;;;yBACpC,CAAA,KAAK,GAAG,IAAI,CAAC,MAAM,CAAA;oBAClB,SAAS,GAAmB,EAAE,CAAC;oBACrC,WAAM,YAAY,CAAC,YAAY,CAAC,KAAK,CAAC,EAAA;;oBAAtC,SAAsC,CAAC;oBACnC,SAAS,GAAG,CAAC,CAAC;oBACd,UAAU,GAAG,CAAC,CAAC;yBACf,CAAC,kBAAkB,EAAnB,cAAmB;oBACN,WAAM,OAAO,CAAC,QAAQ,EAAE,EAAA;;oBAAvC,YAAY,GAAG,SAAwB,CAAC;;;yBAEnC,CAAA,kBAAkB,CAAC,CAAC,CAAC,SAAS,GAAG,IAAI,CAAC,eAAe,CAAC,CAAC,CAAC,IAAI,CAAA;oBAC7C,WAAM,YAAY,CAAC,IAAI,EAAE,EAAA;;oBAAvC,WAAW,GAAG,SAAyB;oBAI7C,IAAI,kBAAkB,IAAI,WAAW,CAAC,IAAI,EAAE;wBAC1C,OAAO,CAAC,IAAI,CACR,oCAAoC;6BACjC,IAAI,CAAC,eAAe,OAAI,CAAA;4BAC3B,kDAAkD;6BAC/C,SAAS,eAAY,CAAA;4BACxB,6CAA6C;4BAC7C,2DAA2D;4BAC3D,yBAAyB;6BACtB,IAAI,CAAC,eAAe,GAAG,IAAI,CAAC,MAAM,gBAAa,CAAA;4BAClD,0DAA0D;4BAC1D,eAAe,CAAC,CAAC;wBACrB,eAAM;qBACP;yBAGG,CAAA,WAAW,CAAC,KAAK,IAAI,IAAI,CAAA,EAAzB,eAAyB;oBACrB,OAAO,GACT,6BAA6B,CAAC,KAAK,EAAE,WAAW,CAAC,KAAK,CAAC,CAAC;oBACtD,SAAS,GAAmB,EAAE,CAAC;oBACrC,SAAS,CAAC,OAAO,CAAC,GAAG,UAAU,CAAC;oBAChC,SAAS,CAAC,MAAM,CAAC,GAAG,OAAO,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;oBAExC,WAAM,YAAY,CAAC,YAAY,CAAC,UAAU,EAAE,SAAS,CAAC,EAAA;;oBAAtD,SAAsD,CAAC;oBAIjD,IAAI,GAAG,aAAa,CAAC,OAAO,CAAC,CAAC;oBACpC,GAAG,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC;oBACrB,KAAS,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,SAAS,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;wBACnC,KAAK,GAAG,SAAS,CAAC,CAAC,CAAC,CAAC;wBACrB,GAAG,GAAG,IAAI,CAAC,CAAC,CAAC,CAAC;wBACpB,SAAS,CAAC,KAAK,CAAC,GAAG,GAAG,CAAC;wBACvB,GAAG,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;qBACf;oBAED,WAAM,YAAY,CAAC,UAAU,CAAC,UAAU,EAAE,SAAS,CAAC,EAAA;;oBAApD,SAAoD,CAAC;oBACrD,2BAAoB,CAAC,SAAS,CAAC,CAAC;oBAEhC,UAAU,EAAE,CAAC;oBACb,SAAS,EAAE,CAAC;;;yBAGV,CAAA,kBAAkB,CAAC,CAAC,CAAC,SAAS,IAAI,IAAI,CAAC,eAAe,CAAC,CAAC;wBACnC,WAAW,CAAC,IAAI,CAAA,EADrC,eACqC;yBAEnC,YAAY,EAAZ,eAAY;oBACV,OAAO,SAAc,CAAC;yBACtB,eAAe,CAAC,IAAI,CAAC,cAAc,CAAC,EAApC,eAAoC;oBAC5B,KAAA,sBAAM,CAAA;oBAAC,WAAM,KAAK,CAAC,eAAe,CACxC,IAAI,CAAC,cAAc,EAAE,EAAC,OAAO,EAAE,IAAI,CAAC,iBAAiB,EAAC,CAAC,EAAA;;oBAD3D,OAAO,GAAG,kBAAO,SAC0C,EAAC,CAAC;;;oBAE7D,OAAO,GAAG,sBAAM,CAAC,KAAK,CAAC,QAAQ,CAAC,KAAK,EAAE,KAAK,EAAE;wBAC5C,SAAS,EAAE,IAAI,CAAC,mBAAmB,IAAI,IAAI,CAAC,CAAC;4BACzC,6BAA6B,CAAC,CAAC;4BAC/B,IAAI,CAAC,mBAAmB;wBAC5B,OAAO,EAAE,CAAC;qBACX,CAAC,CAAC,CAAC;;;oBAEN,KAAS,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,KAAK,CAAC,YAAY,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;wBAClD,SAAS,CAAC,SAAO,KAAK,CAAC,YAAY,CAAC,CAAC,CAAG,CAAC,GAAG,OAAO,CAAC,CAAC,CAAC,CAAC;qBACxD;;yBAOH,eAAM;;oBAGR,IAAI,KAAK,CAAC,aAAa,EAAE;wBACvB,eAAM;qBACP;;yBAEH,WAAM,YAAY,CAAC,UAAU,CAAC,KAAK,EAAE,SAAS,CAAC,EAAA;;oBAA/C,SAA+C,CAAC;oBAChD,KAAK,EAAE,CAAC;oBACR,IAAI,KAAK,CAAC,aAAa,EAAE;wBACvB,eAAM;qBACP;;yBAEH,WAAM,YAAY,CAAC,UAAU,EAAE,EAAA;;oBAA/B,SAA+B,CAAC;oBAChC,WAAM,KAAK,CAAC,OAAO,CAAC,QAAQ,EAAE,EAAA;;oBAA9B,SAA8B,CAAC;oBAC/B,WAAO,KAAK,CAAC,OAAO,EAAC;;oBAErB,KAAK,CAAC,UAAU,GAAG,KAAK,CAAC;;;;;;CAE5B;AA7LD,gCA6LC;AAGD,0BACI,OAAmB,EAAE,IAA4B;IAEnD,IAAI,aAAa,GAAW,IAAI,CAAC;IACjC,IAAI,IAAI,CAAC,eAAe,IAAI,IAAI,EAAE;QAChC,aAAa,GAAG,IAAI,CAAC,eAAe,CAAC;KACtC;SAAM,IAAI,MAAM,CAAC,QAAQ,CAAC,OAAO,CAAC,IAAI,CAAC,EAAE;QACxC,aAAa,GAAG,OAAO,CAAC,IAAI,CAAC;KAC9B;IACD,OAAO,aAAa,CAAC;AACvB,CAAC;AAID,yBACI,OAKwD;IAC1D,OAAO,CAAC,OAAQ,OAAsB,CAAC,QAAQ,KAAK,UAAU,CAAC,CAAC;AAClE,CAAC;AAID,8BAAiC,QACe;IAC9C,OAAO,CAAC,OAAQ,QAA4B,CAAC,IAAI,KAAK,UAAU,CAAC,CAAC;AACpE,CAAC;AAED,yBAGI,KAAU,EAAE,OAAmC,EAC/C,IAA8B;;;;;;oBAChC,IAAI,GAAG,IAAI,IAAI,EAAE,CAAC;oBACZ,UAAU,GAAG,IAAI,CAAC,OAAO,IAAI,IAAI,CAAC;oBAClC,CAAC,GAAG,KAAK,CAAC,YAAY,CAAC;oBACvB,IAAI,GAAiB,EAAE,CAAC;oBAC9B,IAAI,IAAI,CAAC,OAAO,GAAG,CAAC,EAAE;wBACpB,MAAM,IAAI,4BAAmB,CAAC,sCAAsC,CAAC,CAAC;qBACvE;oBAED,GAAG,CAAC,IAAI,CAAC,MAAM,CACX,CAAC,UAAU,IAAI,CAAC,IAAI,CAAC,OAAO,GAAG,CAAC,IAAI,MAAM,CAAC,SAAS,CAAC,IAAI,CAAC,OAAO,CAAC,CAAC,EACnE,4DAA4D;yBACxD,cAAY,IAAI,CAAC,SAAS,CAAC,IAAI,CAAC,OAAO,CAAG,CAAA,CAAC,CAAC;yBAC/B,oBAAoB,CAAC,OAAO,CAAC,EAA7B,cAA6B;oBAC9C,KAAA,OAA0B,CAAA;;wBAC1B,WAAO,OAAsB,CAAC,QAAQ,EAAE,EAAA;;oBAAxC,KAAA,SAAwC,CAAA;;;oBAFtC,YAAY,KAE0B;oBAExC,WAAW,GAAG,CAAC,CAAC;oBAChB,KAAK,GAAG,CAAC,CAAC;;;;;wCAEQ,WAAM,YAAY,CAAC,IAAI,EAAE,EAAA;;oCAAvC,WAAW,GAAG,SAAyB;oCAC7C,IAAI,WAAW,CAAC,KAAK,EAAE;wCAGf,YAAU,6BAA6B,CAAC,KAAK,EAAE,WAAW,CAAC,KAAK,CAAC,CAAC;wCAClE,SAAS,GAAG,GAAG,CAAC,IAAI,CAAC,cAAM,OAAA,CAAC,CAAC,SAAO,CAAC,EAAV,CAAU,CAAC,CAAC;wCAC7C,GAAG,CAAC,OAAO,CAAC,SAAO,CAAC,CAAC;wCAErB,IAAI,KAAK,KAAK,CAAC,EAAE;4CACf,KAAS,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,SAAS,CAAC,MAAM,EAAE,EAAE,CAAC,EAAE;gDACzC,IAAI,CAAC,IAAI,CAAC,iBAAS,CAAC,CAAC,CAAC,CAAC,CAAC;6CACzB;yCACF;wCACK,cAAY,SAAO,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;4DAC7B,CAAC;4CACR,IAAM,QAAQ,GAAG,SAAS,CAAC,CAAC,CAAC,CAAC;4CAC9B,IAAM,SAAS,GAAG,IAAI,CAAC,CAAC,CAAC,CAAC;4CAC1B,IAAI,CAAC,CAAC,CAAC,GAAG,GAAG,CAAC,IAAI,CACd,cAAM,OAAA,GAAG,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,CAAC,EAAE,GAAG,CAAC,GAAG,CAAC,iBAAS,CAAC,WAAS,CAAC,EAAE,QAAQ,CAAC,CAChD,EADR,CACQ,CAAC,CAAC;4CACpB,IAAI,KAAK,GAAG,CAAC,EAAE;gDACb,GAAG,CAAC,OAAO,CAAC,SAAS,CAAC,CAAC;6CACxB;wCACH,CAAC;wCATD,KAAS,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,SAAS,CAAC,MAAM,EAAE,EAAE,CAAC;oDAAhC,CAAC;yCAST;wCACD,GAAG,CAAC,OAAO,CAAC,SAAS,CAAC,CAAC;wCACvB,WAAW,IAAI,WAAS,CAAC;wCAEzB,EAAE,KAAK,CAAC;qCACT;oCACD,IAAI,WAAW,CAAC,IAAI,EAAE;wCACpB,IAAI,UAAU,EAAE;4CACd,OAAO,CAAC,IAAI,CACR,kEAAkE;gDAClE,8CAA8C;gDAC9C,0CAA0C;iDAC1C,4BAA0B,IAAI,CAAC,OAAO,gBAAa,CAAA;gDACnD,0DAA0D;gDAC1D,eAAe,CAAC,CAAC;yCACtB;;qCAEF;;;;;;;yBAzCI,CAAA,UAAU,CAAC,CAAC,CAAC,KAAK,GAAG,IAAI,CAAC,OAAO,CAAC,CAAC,CAAC,IAAI,CAAA;;;;;;;;wCA2CtC,CAAC;wBACR,IAAM,SAAS,GAAG,IAAI,CAAC,CAAC,CAAC,CAAC;wBAC1B,IAAI,CAAC,CAAC,CAAC;4BACH,GAAG,CAAC,IAAI,CAAC,cAAM,OAAA,GAAG,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,CAAC,EAAE,iBAAS,CAAC,WAAW,CAAC,CAAe,EAAtD,CAAsD,CAAC,CAAC;wBAC3E,GAAG,CAAC,OAAO,CAAC,SAAS,CAAC,CAAC;oBACzB,CAAC;oBALD,KAAS,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,IAAI,CAAC,MAAM,EAAE,EAAE,CAAC;gCAA3B,CAAC;qBAKT;oBAED,WAAO,gCAAgB,CAAC,IAAI,CAAC,EAAC;;;;CAC/B;AA1ED,0CA0EC","sourcesContent":[null]}},"hash":"f68a5470a586c10d9bfd0ceaaa4abf50","cacheData":{"env":{}}}